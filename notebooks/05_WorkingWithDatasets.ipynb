{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 11:51:47,769 - azureml.core.workspace - INFO - Found the config file in: /home/yuvraj/projects/AzureAworkspace/azureds/.azureml/config.json\n",
      "Ready to use Azure ML 1.2.0 to work with azml-workspace\n",
      "Imported workspace as ws\n",
      "2020-04-01 11:51:48,990 - root - INFO - Defined global variable `ws` and `conf_catalog`\n"
     ]
    }
   ],
   "source": [
    "%reload_azureml_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Azure Datasets\n",
    "\n",
    "An Azure [***Dataset***](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py) represents a resource for \n",
    "\n",
    "- exploring,\n",
    "- transforming, and\n",
    "- managing \n",
    "\n",
    "data in AzureML.\n",
    "\n",
    "Datasets are the recommended way to work with data, and are the primary mechanism for advanced Azure Machine Learning capabilities like data labeling and data drift monitoring.\n",
    "\n",
    ">*** A Dataset is a reference to data in a Datastore or behind public web urls.***\n",
    "\n",
    "## 1.1 Type of Azure Datasets \n",
    "\n",
    "You can create the following types of dataset:\n",
    "\n",
    "- ***Tabular*** : The data is read from the dataset as a table. You should use this type of dataset when your data is consistently structured and you want to work with it in common tabular data structures, such as Pandas dataframes.\n",
    "\n",
    "- ***File*** : The dataset presents a list of file paths that can be read as though from the file system. Use this type of dataset when your data is unstructured, or when you need to process the data at the file level (for example, to train a convolutional neural network from a set of image files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating and Registering Tabular Datasets\n",
    "\n",
    "## 2.1 Create Tabular Dataset\n",
    "To create a tabular dataset using the SDK, use the from_delimited_files method of the Dataset.Tabular class, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 11:51:49,005 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f0ff822ff60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvraj/anaconda3/envs/AzureDS/lib/python3.6/site-packages/_pytest/mark/structures.py:443: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds,'01_raw/*.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Register Tabular Dataset\n",
    "We will register the tabular dataset as Iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the tabular dataset\n",
    "tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                   name='Iris Dataset',\n",
    "                                   description='iris data',\n",
    "                                   tags = {'format':'CSV'},\n",
    "                                   create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Creating and Registering File Datasets\n",
    "\n",
    "To create a file dataset using the SDK, use the from_files method of the Dataset.File class, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 11:51:55,047 - azureml.core.run - INFO - Could not load the run context. Logging offline\n",
      "/iris.csv\n",
      "Dataset File already registered\n"
     ]
    }
   ],
   "source": [
    "#Create a file dataset from the path on the datastore (this may take a short while)\n",
    "file_data_set = Dataset.File.from_files(path=(default_ds, '01_raw/*.csv'))\n",
    "\n",
    "# Get the files in the dataset\n",
    "for file_path in file_data_set.to_path():\n",
    "    print(file_path)\n",
    "\n",
    "try:\n",
    "    # Register the file dataset\n",
    "    file_data_set = file_data_set.register(workspace=ws, \n",
    "                                       name='Iris Files Dataset',\n",
    "                                       description='Iris file dataset',\n",
    "                                       tags = {'format':'CSV'},\n",
    "                                       create_new_version=True)\n",
    "    print('Datasets registered')\n",
    "except:\n",
    "    print('Dataset File already registered')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view and manage datasets on the Datasets page for your workspace in Azure ML Studio. You cal also get a list of datasets from the workspace object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "2020-04-01 11:51:59,008 - azureml.core.run - INFO - Could not load the run context. Logging offline\n",
      "\t diabetes file dataset version 1\n",
      "2020-04-01 11:51:59,584 - azureml.core.run - INFO - Could not load the run context. Logging offline\n",
      "\t Iris Dataset version 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieving a Registered Dataset\n",
    "After registering a dataset, you can retrieve it by using any of the following techniques:\n",
    "\n",
    "- The ***datasets*** dictionary attribute of a ***Workspace*** object.\n",
    "- The ***get_by_name*** or ***get_by_id*** method of the ***Dataset*** class.\n",
    "\n",
    "Both of these techniques are shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 11:52:00,338 - azureml.core.run - INFO - Could not load the run context. Logging offline\n",
      "2020-04-01 11:52:01,672 - azureml.core.run - INFO - Could not load the run context. Logging offline\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Get a dataset from the workspace datasets collection\n",
    "ds1 = ws.datasets['Iris Dataset']\n",
    "\n",
    "# Get a dataset by name from the datasets class\n",
    "ds2 = Dataset.get_by_name(ws, 'Iris Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 11:52:01,703 - azureml.core.run - INFO - Could not load the run context. Logging offline\n"
     ]
    }
   ],
   "source": [
    "# Display the first 20 rows as a Pandas dataframe\n",
    "\n",
    "data = ds1.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 11:52:02,849 - azureml.core.run - INFO - Could not load the run context. Logging offline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('azuremlprimary', '01_raw/*.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"263d5808-7443-4572-b5f1-79a55d499163\",\n",
       "    \"name\": \"Iris Dataset\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"iris data\",\n",
       "    \"tags\": {\n",
       "      \"format\": \"CSV\"\n",
       "    },\n",
       "    \"workspace\": \"Workspace.create(name='azml-workspace', subscription_id='797942f9-de86-4b1e-8b36-7ba7238edc7b', resource_group='aml-resources')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ws.datasets.get('Iris Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
