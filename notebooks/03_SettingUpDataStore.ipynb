{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro\n",
    "%reload_azureml_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview, this tutorial will:\n",
    "\n",
    "1. Explain Azure Datastores, and its different types. \n",
    "2. Recommended workflow with working with datastores.\n",
    "3. How to add a datastore to an azureml workspace.\n",
    "4. How to manage datastores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datastores\n",
    "\n",
    "In Azure Machine Learning, datastores are abstraction/connectors for cloud data sources. They contain all the information required to connect to data sources. They can be used to:\n",
    "\n",
    "* Ingest Data into experiment\n",
    "* Write Outputs from an experiment\n",
    "\n",
    "### 1.1 Type of Datastore\n",
    "\n",
    "Azure Machine Learning supports the creation of <b> datastores </b> for multiple kinds of Azure data source, including:\n",
    "\n",
    "* Azure Storage (blob and file containers)\n",
    "* Azure Data Lake stores\n",
    "* Azure SQL Database\n",
    "* Azure Databricks file system (DBFS)\n",
    "\n",
    "### 1.2 Recommended Azure Machine Learning Data Workflow\n",
    "\n",
    "This workflow assumes you have an Azure storage account and data in a cloud-based storage service in Azure.\n",
    "\n",
    "1. Create an Azure Machine Learning datastore to store connection information to your Azure storage.\n",
    "\n",
    "2. From that datastore, create an Azure Machine Learning dataset to point to a specific file(s) in your underlying storage.\n",
    "\n",
    "3. To use that dataset in your machine learning experiment you can either\n",
    "\n",
    "   * a. Mount it to your experiment's compute target for model training.\n",
    "    \n",
    "    OR\n",
    "\n",
    "   * b. consume it directly in Azure Machine Learning solutions like, automated machine learning (automated ML) experiment runs, machine learning pipelines, or the Azure Machine Learning designer.\n",
    "\n",
    "4. Create dataset monitors for your model output dataset to detect for data drift.\n",
    "\n",
    "5. If data drift is detected, update your input dataset and retrain your model accordingly.\n",
    "\n",
    "The following diagram provides a visual demonstration of this recommended workflow.\n",
    "<img src=\"https://docs.microsoft.com/en-gb/azure/machine-learning/media/concept-data/data-concept-diagram.svg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding Data Stores to a Workspace\n",
    "\n",
    "Every workspace has two built-in datastores:\n",
    "\n",
    "* an Azure Storage blob container, and\n",
    "* an Azure Storage file container)\n",
    "\n",
    "that are used as system storage by Azure Machine Learning. You can also store a limited amount of your own data in these built-in datastores for experiments, model training, and so on.\n",
    "\n",
    "However, in most machine learning projects, you will likely need to work with data sources of your own - either because you need to store larger volumes of data than the built-in datastores support, or because you need to integrate your machine learning solution with data from existing applications.\n",
    "\n",
    "## 2.1 Registering a Datastore\n",
    "\n",
    "To add a datastore to your workspace, you can register it using the graphical interface in Azure Machine Learning Studio, or you can use the Azure Machine Learning SDK. For example, the following code registers an Azure Storage blob container as a datastore named <b>blob_data</b>.\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register a new datastore\n",
    "blob_ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                  datastore_name='blob_data', \n",
    "                                                  container_name='data_container',\n",
    "                                                  account_name='az_store_acct',\n",
    "                                                  account_key='123456abcde789â€¦')\n",
    "```\n",
    "\n",
    "The above code sample show how to registew a blob container with datastore. Datastore offer several other functions inluding:\n",
    "\n",
    "* register_azure_data_lake\n",
    "* register_azure_data_lake_gen2\n",
    "* register_azure_sql_database\n",
    "* register_azure_postgre_sql\n",
    "* register_azure_my_sql\n",
    "\n",
    "Sample of this code can he found [here](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-data-transfer.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msrest.exceptions import HttpOperationError\n",
    "from azureml.core import Workspace, Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "blob_datastore_name = conf_catalog['azuremlprimary']['storage_name']\n",
    "account_name        = conf_catalog['azuremlprimary']['storage_name']   # Storage account name\n",
    "container_name      = conf_catalog['azuremlprimary']['container_name'] # Name of Azure blob container\n",
    "account_key         = conf_catalog['azuremlprimary']['key']            # Storage account key\n",
    "\n",
    "# Register a new datastore\n",
    "try:\n",
    "    blob_datastore = blob_datastore = Datastore.get(ws, blob_datastore_name)\n",
    "    print(\"Found Blob Datastore with name: %s\" % blob_datastore_name)\n",
    "except HttpOperationError:\n",
    "\n",
    "    blob_datastore = Datastore.register_azure_blob_container(workspace = ws, \n",
    "                                                      datastore_name = blob_datastore_name, \n",
    "                                                      container_name = container_name,\n",
    "                                                      account_name = account_name,\n",
    "                                                      account_key = account_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Managing Datastores\n",
    "\n",
    "You can view and manage datastores in Azure Machine Learning Studio, or you can use the Azure Machine Learning SDK. For example, the following code lists the names of each datastore in the workspace.\n",
    "\n",
    ">```python\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)\n",
    "```\n",
    "\n",
    "You can get a reference to any datastore by using the Datastore.get() method as shown here:\n",
    "\n",
    ">```python\n",
    "blob_store = Datastore.get(ws, datastore_name='blob_data')\n",
    "    print(ds_name)\n",
    "```\n",
    "\n",
    "The workspace always includes a default datastore (initially, this is the built-in workspaceblobstore datastore), which you can retrieve by using the get_default_datastore() method of a Workspace object, like this:\n",
    "\n",
    ">```python\n",
    "default_store = ws.get_default_datastore()\n",
    "```\n",
    "\n",
    "To change the default datastore, use the set_default_datastore() method:\n",
    "\n",
    "\n",
    ">```python\n",
    "ws.set_default_datastore('blob_data')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)\n",
    "    \n",
    "# Get datastore\n",
    "from azureml.core import Datastore\n",
    "\n",
    "blob_store = Datastore.get(ws, datastore_name='azuremlprimary')\n",
    "print('Default Properties:' + blob_store.name,\":\", blob_store.datastore_type + \" (\" + blob_store.account_name + \")\")\n",
    "\n",
    "# Set defauws.set_default_datastore('azuremlprimary')\n",
    "ws.set_default_datastore('azuremlprimary')\n",
    "default_ds = ws.get_default_datastore()\n",
    "print('Default Datastore: '+default_ds.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
