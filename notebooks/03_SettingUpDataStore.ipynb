{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-29 21:43:53,430 - root - INFO - ** Kedro project AzureDataScience\n",
      "2020-03-29 21:43:53,431 - root - INFO - Defined global variable `context` and `catalog`\n",
      "\u001b[33mTraceback (most recent call last):\n",
      "  File \"/home/yuvraj/anaconda3/envs/AzureDS/lib/python3.6/site-packages/kedro/cli/cli.py\", line 594, in load_entry_points\n",
      "    entry_point_commands.append(entry_point.load())\n",
      "  File \"/home/yuvraj/.local/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2442, in load\n",
      "    self.require(*args, **kwargs)\n",
      "  File \"/home/yuvraj/.local/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2465, in require\n",
      "    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n",
      "  File \"/home/yuvraj/.local/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
      "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
      "pkg_resources.ContextualVersionConflict: (pandas 0.23.4 (/home/yuvraj/anaconda3/envs/AzureDS/lib/python3.6/site-packages), Requirement.parse('pandas<1.0,>=0.24.0'), {'kedro'})\n",
      "\u001b[0m\u001b[31mError: Loading line_magic commands from line_magic = kedro_viz.server:run_viz\u001b[0m\n",
      "2020-03-29 21:43:53,440 - azureml.core.workspace - INFO - Found the config file in: /home/yuvraj/projects/AzureAworkspace/azureds/.azureml/config.json\n",
      "2020-03-29 21:43:53,442 - adal-python - INFO - fbb122df-71f7-4fd1-8696-3a47cef737f9 - CacheDriver:Cached token is expired at 2020-03-29 17:46:54.929587.  Refreshing\n",
      "2020-03-29 21:43:53,444 - adal-python - INFO - fbb122df-71f7-4fd1-8696-3a47cef737f9 - TokenRequest:Getting a new token from a refresh token\n",
      "2020-03-29 21:43:53,999 - adal-python - INFO - fbb122df-71f7-4fd1-8696-3a47cef737f9 - CacheDriver:Returning token refreshed after expiry.\n",
      "Ready to use Azure ML 1.2.0 to work with azml-workspace\n",
      "Imported workspace as ws\n",
      "2020-03-29 21:43:55,337 - root - INFO - Defined global variable `ws` and `conf_catalog`\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro\n",
    "%reload_azureml_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview, this tutorial will:\n",
    "\n",
    "1. Explain Azure Datastores, and its different types. \n",
    "2. Recommended workflow with working with datastores.\n",
    "3. How to add a datastore to an azureml workspace.\n",
    "4. How to manage datastores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datastores\n",
    "\n",
    "In Azure Machine Learning, datastores are abstraction/connectors for cloud data sources. They contain all the information required to connect to data sources. They can be used to:\n",
    "\n",
    "* Ingest Data into experiment\n",
    "* Write Outputs from an experiment\n",
    "\n",
    "### 1.1 Type of Datastore\n",
    "\n",
    "Azure Machine Learning supports the creation of <b> datastores </b> for multiple kinds of Azure data source, including:\n",
    "\n",
    "* Azure Storage (blob and file containers)\n",
    "* Azure Data Lake stores\n",
    "* Azure SQL Database\n",
    "* Azure Databricks file system (DBFS)\n",
    "\n",
    "### 1.2 Recommended Azure Machine Learning Data Workflow\n",
    "\n",
    "This workflow assumes you have an Azure storage account and data in a cloud-based storage service in Azure.\n",
    "\n",
    "1. Create an Azure Machine Learning datastore to store connection information to your Azure storage.\n",
    "\n",
    "2. From that datastore, create an Azure Machine Learning dataset to point to a specific file(s) in your underlying storage.\n",
    "\n",
    "3. To use that dataset in your machine learning experiment you can either\n",
    "\n",
    "   * a. Mount it to your experiment's compute target for model training.\n",
    "    \n",
    "    OR\n",
    "\n",
    "   * b. consume it directly in Azure Machine Learning solutions like, automated machine learning (automated ML) experiment runs, machine learning pipelines, or the Azure Machine Learning designer.\n",
    "\n",
    "4. Create dataset monitors for your model output dataset to detect for data drift.\n",
    "\n",
    "5. If data drift is detected, update your input dataset and retrain your model accordingly.\n",
    "\n",
    "The following diagram provides a visual demonstration of this recommended workflow.\n",
    "<img src=\"https://docs.microsoft.com/en-gb/azure/machine-learning/media/concept-data/data-concept-diagram.svg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-29 21:43:55,663 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed73825f8>\n",
      "2020-03-29 21:43:58,499 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed73825f8>\n",
      "azuremlprimary - Default = True\n",
      "workspaceblobstore - Default = False\n",
      "workspacefilestore - Default = False\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding Data Stores to a Workspace\n",
    "\n",
    "Every workspace has two built-in datastores:\n",
    "\n",
    "* an Azure Storage blob container, and\n",
    "* an Azure Storage file container)\n",
    "\n",
    "that are used as system storage by Azure Machine Learning. You can also store a limited amount of your own data in these built-in datastores for experiments, model training, and so on.\n",
    "\n",
    "However, in most machine learning projects, you will likely need to work with data sources of your own - either because you need to store larger volumes of data than the built-in datastores support, or because you need to integrate your machine learning solution with data from existing applications.\n",
    "\n",
    "## 2.1 Registering a Datastore\n",
    "\n",
    "To add a datastore to your workspace, you can register it using the graphical interface in Azure Machine Learning Studio, or you can use the Azure Machine Learning SDK. For example, the following code registers an Azure Storage blob container as a datastore named <b>blob_data</b>.\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register a new datastore\n",
    "blob_ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                  datastore_name='blob_data', \n",
    "                                                  container_name='data_container',\n",
    "                                                  account_name='az_store_acct',\n",
    "                                                  account_key='123456abcde789â€¦')\n",
    "```\n",
    "\n",
    "The above code sample show how to registew a blob container with datastore. Datastore offer several other functions inluding:\n",
    "\n",
    "* register_azure_data_lake\n",
    "* register_azure_data_lake_gen2\n",
    "* register_azure_sql_database\n",
    "* register_azure_postgre_sql\n",
    "* register_azure_my_sql\n",
    "\n",
    "Sample of this code can he found [here](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-data-transfer.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-29 21:44:30,561 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed73825f8>\n",
      "Found Blob Datastore with name: azuremlprimary\n"
     ]
    }
   ],
   "source": [
    "from msrest.exceptions import HttpOperationError\n",
    "from azureml.core import Workspace, Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "blob_datastore_name = conf_catalog['azuremlprimary']['storage_name']\n",
    "account_name        = conf_catalog['azuremlprimary']['storage_name']   # Storage account name\n",
    "container_name      = conf_catalog['azuremlprimary']['container_name'] # Name of Azure blob container\n",
    "account_key         = conf_catalog['azuremlprimary']['key']            # Storage account key\n",
    "\n",
    "# Register a new datastore\n",
    "try:\n",
    "    blob_datastore = blob_datastore = Datastore.get(ws, blob_datastore_name)\n",
    "    print(\"Found Blob Datastore with name: %s\" % blob_datastore_name)\n",
    "except HttpOperationError:\n",
    "\n",
    "    blob_datastore = Datastore.register_azure_blob_container(workspace = ws, \n",
    "                                                      datastore_name = blob_datastore_name, \n",
    "                                                      container_name = container_name,\n",
    "                                                      account_name = account_name,\n",
    "                                                      account_key = account_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Managing Datastores\n",
    "\n",
    "You can view and manage datastores in Azure Machine Learning Studio, or you can use the Azure Machine Learning SDK. For example, the following code lists the names of each datastore in the workspace.\n",
    "\n",
    ">```python\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)\n",
    "```\n",
    "\n",
    "You can get a reference to any datastore by using the Datastore.get() method as shown here:\n",
    "\n",
    ">```python\n",
    "blob_store = Datastore.get(ws, datastore_name='blob_data')\n",
    "    print(ds_name)\n",
    "```\n",
    "\n",
    "The workspace always includes a default datastore (initially, this is the built-in workspaceblobstore datastore), which you can retrieve by using the get_default_datastore() method of a Workspace object, like this:\n",
    "\n",
    ">```python\n",
    "default_store = ws.get_default_datastore()\n",
    "```\n",
    "\n",
    "To change the default datastore, use the set_default_datastore() method:\n",
    "\n",
    "\n",
    ">```python\n",
    "ws.set_default_datastore('blob_data')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-29 17:02:37,597 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed7a16ba8>\n",
      "azuremlprimary\n",
      "workspaceblobstore\n",
      "workspacefilestore\n",
      "2020-03-29 17:02:39,487 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed7a16ba8>\n",
      "Default Properties:azuremlprimary : AzureBlob (azuremlprimary)\n",
      "2020-03-29 17:02:40,045 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed7a16ba8>\n",
      "2020-03-29 17:02:40,541 - azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f8ed7a16ba8>\n",
      "Default Datastore: azuremlprimary\n"
     ]
    }
   ],
   "source": [
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)\n",
    "    \n",
    "# Get datastore\n",
    "from azureml.core import Datastore\n",
    "\n",
    "blob_store = Datastore.get(ws, datastore_name='azuremlprimary')\n",
    "print('Default Properties:' + blob_store.name,\":\", blob_store.datastore_type + \" (\" + blob_store.account_name + \")\")\n",
    "\n",
    "# Set defauws.set_default_datastore('azuremlprimary')\n",
    "ws.set_default_datastore('azuremlprimary')\n",
    "default_ds = ws.get_default_datastore()\n",
    "print('Default Datastore: '+default_ds.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
