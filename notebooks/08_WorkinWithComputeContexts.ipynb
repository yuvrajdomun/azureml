{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_azureml_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Azure Environments \n",
    "Python code runs in the context of a virtual environment that defines the version of the Python runtime to be used as well as the installed packages available to the code. In most Python installations, packages are installed and managed in environments using ***Conda*** or ***pip***.\n",
    "\n",
    "## 1.1 Environments in Azure Machine Learning\n",
    "In general, Azure Machine Learning handles environment creation and package installation for you - usually through the creation of Docker containers. You can specify the Conda or pip packages you need, and have Azure Machine Learning create an environment for the experiment.\n",
    "\n",
    "In an enterprise machine learning solution, where experiments may be run in a variety of compute contexts, it can be important to be aware of the environments in which your experiment code is running. Environments are encapsulated by the Environment class; which you can use to create environments and specify runtime configuration for an experiment.\n",
    "\n",
    "You can have Azure Machine Learning manage environment creation and package installation to define an environment, and then register it for reuse. Alternatively, you can manage your own environments and register them. This makes it possible to define consistent, reusable runtime contexts for your experiments - regardless of where the experiment script is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Creating Environments\n",
    "\n",
    "There are a number of ways environment are created in the Azure Machine Learning, including when you:\n",
    "\n",
    "- Initialize a new Environment object.\n",
    "\n",
    "- Use one of the Environment class methods: \n",
    "\n",
    "    - [from_conda_specification(name, file_path)](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py#from-conda-specification-name--file-path-),\n",
    "    - [from_pip_requirements(name, file_path), or](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py#from-pip-requirements-name--file-path-)\n",
    "    - [from_existing_conda_environment(name, conda_environment_name)](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py#from-existing-conda-environment-name--conda-environment-name-).\n",
    "    \n",
    "\n",
    "- Use the submit(config, tags=None, **kwargs) method of the Experiment class to submit an experiment run without specifying an environment, including with an Estimator object.\n",
    "\n",
    "> ####  ***Creating an Environment from a Specification File***\n",
    "If you have an existing Conda environment defined on your workstation, you can use it to define an Azure Machine Learning environment:\n",
    "```python\n",
    "from azureml.core import Environment\n",
    "env = Environment.from_existing_conda_environment(name='training_environment',\n",
    "                                                  conda_environment_name='py_env')\n",
    "```\n",
    "\n",
    "\n",
    "> ####  ***Creating an Environment by Specifying Packages***\n",
    "You can define an environment by specifying the Conda and pip packages you need in a CondaDependencies object, like this:\n",
    "```python\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "env = Environment('training_environment')\n",
    "deps = CondaDependencies.create(conda_packages=['scikit-learn','pandas','numpy'],\n",
    "                                pip_packages=['azureml-defaults'])\n",
    "env.python.conda_dependencies = deps\n",
    "```\n",
    "\n",
    "In the example below, we will create our azureDS environment from a ***requirements.txt***:\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "env = Environment.from_pip_requirements(name = 'azureDS',\n",
    "                                        file_path = 'requirements.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Register and Retrieve Environments\n",
    "\n",
    "Having gone to the trouble of defining an environment with the packages you need, you can register it in the workspace.\n",
    "\n",
    "Use the register method of an Environment object to register an environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the environment\n",
    "env.register(workspace=ws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the environment is registered with the name you assigned when you first created it (in this case, *diabetes-experiment-env*).\n",
    "\n",
    "With the environment registered, you can reuse it for any scripts that have the same requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the registered environments in your workspace like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_names = Environment.list(workspace=ws)\n",
    "for env_name in env_names:\n",
    "    print('Name:',env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Retrieving and using an Environment\n",
    "\n",
    "You can retrieve a registered environment by using the get method of the Environment class, and then assign it to a ScriptRunConfig or Estimator.\n",
    "\n",
    "For example, the following code sample retrieves the training_environment registered environment, and assigns it to an estimator:\n",
    "\n",
    "```python\n",
    "from azureml.core import Environment, Estimator\n",
    "\n",
    "training_env = Environment.get(workspace=ws, name='training_environment')\n",
    "estimator = Estimator(source_directory='experiment_folder'\n",
    "                      entry_script='training_script.py',\n",
    "                      compute_target='local',\n",
    "                      environment_definition=training_env)\n",
    "```\n",
    "When an experiment based on the estimator is run, Azure Machine Learning will look for an existing environment that matches the definition, and if none is found a new environment will be created based on the registered environment specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Environment, Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core import Dataset\n",
    "\n",
    "# Get Environment \n",
    "training_env = Environment.get(workspace=ws, name='azureDS')\n",
    "\n",
    "# Get a dataset reference from the workspace datasets collection\n",
    "dataset = Dataset.get_by_name(ws, name='Iris Dataset')\n",
    "\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory='src/azureds_util',\n",
    "                      inputs=[dataset.as_named_input('iris')],\n",
    "                      entry_script='run_azure.py',\n",
    "                      compute_target='local',\n",
    "                      environment_definition=training_env)\n",
    "\n",
    "# Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'Env_trial')\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Curated Environments\n",
    "\n",
    "Azure Machine Learning includes a selection of pre-defined curated environments that reflect common usage scenarios. These include environments that are pre-configured with package dependencies for common frameworks, such as Scikit-Learn, PyTorch, Tensorflow, and others.\n",
    "\n",
    "Curated environments are registered in all Azure Machine Learning workspaces with a name that begins ***AzureML-***.\n",
    "\n",
    ">***Note***: You can't register your own environments with an “AzureML-” prefix.\n",
    "\n",
    "To view curated environments and the dependencies they contain, you can run the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "envs = Environment.list(workspace=ws)\n",
    "for env in envs:\n",
    "    if env.startswith(\"AzureML\"):\n",
    "        print(\"Name\",env)\n",
    "        print(\"packages\", envs[env].python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute Targets\n",
    "\n",
    "In Azure Machine Learning, [Compute](https://docs.microsoft.com/en-gb/azure/machine-learning/concept-compute-target) Targets are physical or virtual computers on which experiments are run.\n",
    "\n",
    "### Flexible Compute\n",
    "The ability to assign experiment runs to specific compute targets helps you implement a flexible data science ecosystem in the following ways:\n",
    "\n",
    "- Code can be developed and tested on local or low-cost compute, and then moved to more scalable compute for production workloads.\n",
    "- You can run individual processes on the compute target that best fits its needs. For example, by using GPU-based compute to train deep learning models, and switching to lower-cost CPU-only compute to test and register the trained model.\n",
    "\n",
    "### Cost-Effective Scalability\n",
    "One of the core benefits of cloud computing is the ability to manage costs by paying only for what you use. In Azure Machine Learning, you can take advantage of this principle by defining compute targets that:\n",
    "\n",
    "- Start on-demand and stop automatically when no longer required.\n",
    "- Scale automatically based on workload processing needs.\n",
    "\n",
    "\n",
    "## 2.1 Types of Compute\n",
    "Azure Machine Learning supports multiple types of compute for experimentation and training, and for production inferencing. This enables you to select the most appropriate type of compute target for your particular needs.\n",
    "\n",
    ">### 2.1.1 Local Compute\n",
    "You can specify a local compute target for most processing tasks in Azure Machine Learning. This runs the experiment on the same compute target as the code used to initiate the experiment, which may be you physical workstation or a virtual machine such as an Azure Machine Learning compute instance on which you are running a notebook.\n",
    "Local compute is generally a great choice during development and testing with low to moderate volumes of data.\n",
    "### 2.1.2 Training Clusters\n",
    "For training workloads with high scalability requirements, you can use Azure Machine Learning training clusters; which are multi-node clusters of Virtual Machines that automatically scale up or down to meet demand. This is a cost-effective way to run experiments that need to handle large volumes of data or use parallel processing to distribute the workload and reduce the time it takes to run. <br><br>\n",
    "***Note***: Despite the name, you can also use training clusters to deploy batch inferencing pipelines in production. You'll explore this further later in the course.\n",
    "### 2.1.3 Inference Clusters\n",
    "To deploy trained models as production services, you can use Azure Machine Learning inference clusters, which use containerization technologies to enable rapid initialization of compute for on-demand inferencing.\n",
    "### 2.1.4 Attached Compute\n",
    "If you already use an Azure-based compute environment for data science, such as a virtual machine or an Azure Databricks cluster, you can attach it to your Azure Machine Learning workspace and use it as a compute target for certain types of workload.\n",
    "\n",
    "## 2.2 Create a Compute Target\n",
    "In many cases, your local compute resources may not be sufficient to process a complex or long-running experiment that needs to process a large volume of data; and you may want to take advantage of the ability to dynamically create and use compute resources in the cloud.\n",
    "Azure ML supports a range of compute targets, which you can define in your workpace and use to run experiments; paying for the resources only when using them. When you set up the workspace in the first exercise, you created a training cluster called **aml-cluster**, so let's verify that exists (and if not, create it) so we can use it to run training experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"aml-cluster\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS1_V2', max_nodes=2)\n",
    "    training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "training_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Creating a Managed Compute Target with the SDK***\n",
    "\n",
    "A managed compute target is one that is managed by Azure Machine Learning, such as an Azure Machine Learning training cluster.\n",
    "\n",
    "To create an Azure Machine Learning training cluster compute target, use the azureml.core.compute.ComputeTarget class and the AmlCompute class, like this:\n",
    "\n",
    ">```python\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'aml-cluster'\n",
    "# Define compute configuration\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n",
    "                                                       min_nodes=0, max_nodes=4,\n",
    "                                                       vm_priority='dedicated')\n",
    "# Create the compute\n",
    "aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "aml_cluster.wait_for_completion(show_output=True)\n",
    "```\n",
    "\n",
    "In this example, a cluster with up to four nodes based on the STANDARD_DS12_v2 virtual machine image will be created. The priority for the virtual machines (VMs) is set to dedicated, meaning they are reserved for use in this cluster (the alternative is to specify lowpriority, which has a lower cost but means that the VMs can be pre-empted if a higher-priority workload requires the compute).\n",
    "\n",
    "Note: For a full list of AmlCompute configuration options, see the AmlCompute class SDK documentation.\n",
    "\n",
    "#### ***Attaching an Unmanaged Compute Target with the SDK***\n",
    "\n",
    "An unmanaged compute target is one that is defined and managed outside of the Azure Machine Learning workspace; for example, an Azure virtual machine or an Azure Databricks cluster.\n",
    "\n",
    "The code to attach an existing unmanaged compute target is similar to the code used to create a managed compute target, except that you must use the ComputeTarget.attach() method to attach the existing compute based on its target-specific configuration settings.\n",
    "\n",
    "For example, the following code can be used to attach an existing Azure Databricks cluster:\n",
    "\n",
    ">```python\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'db_cluster'\n",
    "# Define configuration for existing Azure Databricks cluster\n",
    "db_workspace_name = 'db_workspace'\n",
    "db_resource_group = 'db_resource_group'\n",
    "db_access_token = '1234-abc-5678-defg-90...'\n",
    "db_config = DatabricksCompute.attach_configuration(resource_group=db_resource_group,\n",
    "                                                   workspace_name=db_workspace_name,\n",
    "                                                   access_token=db_access_token)\n",
    "# Create the compute\n",
    "databricks_compute = ComputeTarget.attach(ws, compute_name, db_config)\n",
    "databricks_compute.wait_for_completion(True)\n",
    "```\n",
    "\n",
    "#### ***Checking for an Existing Compute Target***\n",
    "\n",
    "\n",
    "In many cases, you will want to check for the existence of a compute target, and only create a new one if there isn't already one with the specified name. To accomplish this, you can catch the ComputeTargetException exception, like this:\n",
    "\n",
    ">```python\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "compute_name = \"aml-cluster\"\n",
    "# Check if the compute target exists\n",
    "try:\n",
    "    aml_cluster = ComputeTarget(workspace=ws, name=compute_name)\n",
    "    print('Found existing cluster.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n",
    "                                                           max_nodes=4)\n",
    "    aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "aml_cluster.wait_for_completion(show_output=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information for creating compute targets can be found here:\n",
    "\n",
    "https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-set-up-training-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
