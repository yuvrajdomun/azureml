{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Workspace\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
    "\n",
    "# Load Credentials\n",
    "from kedro.config import ConfigLoader\n",
    "\n",
    "conf_paths = [\"conf/base\", \"conf/local\"]\n",
    "conf_loader = ConfigLoader(conf_paths)\n",
    "conf_catalog = conf_loader.get(\"credentials*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datastores\n",
    "\n",
    "In Azure Machine Learning, datastores are abstraction/connectors for cloud data sources. They contain all the information required to connect to data sources. They can be used to:\n",
    "\n",
    "* Ingest Data into experiment\n",
    "* Write Outputs from an experiment\n",
    "\n",
    "### 1.1 Type of Datastore\n",
    "\n",
    "Azure Machine Learning supports the creation of <b> datastores </b> for multiple kinds of Azure data source, including:\n",
    "\n",
    "* Azure Storage (blob and file containers)\n",
    "* Azure Data Lake stores\n",
    "* Azure SQL Database\n",
    "* Azure Databricks file system (DBFS)\n",
    "\n",
    "### 1.2 Recommended Azure Machine Learning Data Workflow\n",
    "\n",
    "This workflow assumes you have an Azure storage account and data in a cloud-based storage service in Azure.\n",
    "\n",
    "1. Create an Azure Machine Learning datastore to store connection information to your Azure storage.\n",
    "\n",
    "2. From that datastore, create an Azure Machine Learning dataset to point to a specific file(s) in your underlying storage.\n",
    "\n",
    "3. To use that dataset in your machine learning experiment you can either\n",
    "\n",
    "   * a. Mount it to your experiment's compute target for model training.\n",
    "    \n",
    "    OR\n",
    "\n",
    "   * b. consume it directly in Azure Machine Learning solutions like, automated machine learning (automated ML) experiment runs, machine learning pipelines, or the Azure Machine Learning designer.\n",
    "\n",
    "4. Create dataset monitors for your model output dataset to detect for data drift.\n",
    "\n",
    "5. If data drift is detected, update your input dataset and retrain your model accordingly.\n",
    "\n",
    "The following diagram provides a visual demonstration of this recommended workflow.\n",
    "<img src=\"https://docs.microsoft.com/en-gb/azure/machine-learning/media/concept-data/data-concept-diagram.svg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding Data Stores to a Workspace\n",
    "\n",
    "Every workspace has two built-in datastores:\n",
    "\n",
    "* an Azure Storage blob container, and\n",
    "* an Azure Storage file container)\n",
    "\n",
    "that are used as system storage by Azure Machine Learning. You can also store a limited amount of your own data in these built-in datastores for experiments, model training, and so on.\n",
    "\n",
    "However, in most machine learning projects, you will likely need to work with data sources of your own - either because you need to store larger volumes of data than the built-in datastores support, or because you need to integrate your machine learning solution with data from existing applications.\n",
    "\n",
    "## 2.1 Registering a Datastore\n",
    "\n",
    "To add a datastore to your workspace, you can register it using the graphical interface in Azure Machine Learning Studio, or you can use the Azure Machine Learning SDK. For example, the following code registers an Azure Storage blob container as a datastore named <b>blob_data</b>.\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register a new datastore\n",
    "blob_ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                  datastore_name='blob_data', \n",
    "                                                  container_name='data_container',\n",
    "                                                  account_name='az_store_acct',\n",
    "                                                  account_key='123456abcde789â€¦')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "# Register a new datastore\n",
    "blob_ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                  datastore_name=conf_catalog['azuremlprimary']['storage_name'], \n",
    "                                                  container_name='datacontainer',\n",
    "                                                  account_name=conf_catalog['azuremlprimary']['storage_name'],\n",
    "                                                  account_key=conf_catalog['azuremlprimary']['key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing Datastores\n",
    "\n",
    "You can view and manage datastores in Azure Machine Learning Studio, or you can use the Azure Machine Learning SDK. For example, the following code lists the names of each datastore in the workspace.\n",
    "\n",
    ">```python\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)\n",
    "```\n",
    "\n",
    "You can get a reference to any datastore by using the Datastore.get() method as shown here:\n",
    "\n",
    ">```python\n",
    "blob_store = Datastore.get(ws, datastore_name='blob_data')\n",
    "    print(ds_name)\n",
    "```\n",
    "\n",
    "The workspace always includes a default datastore (initially, this is the built-in workspaceblobstore datastore), which you can retrieve by using the get_default_datastore() method of a Workspace object, like this:\n",
    "\n",
    ">```python\n",
    "default_store = ws.get_default_datastore()\n",
    "```\n",
    "\n",
    "To change the default datastore, use the set_default_datastore() method:\n",
    "\n",
    "\n",
    ">```python\n",
    "ws.set_default_datastore('blob_data')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name in ws.datastores:\n",
    "    print(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_store = Datastore.get(ws, datastore_name='azuremlprimary')\n",
    "\n",
    "ws.set_default_datastore('azuremlprimary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
