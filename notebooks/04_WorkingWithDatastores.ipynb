{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Azure Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_azureml_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get datastores from workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data Store from workspace\n",
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "# List all datastores registered in the current workspace\n",
    "datastores = ws.datastores\n",
    "for name, datastore in datastores.items():\n",
    "    print(name, datastore.datastore_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get a specific datastore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a named datastore from the current workspace\n",
    "datastore = Datastore.get(ws, datastore_name='azuremlprimary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Uploading and Download Data to Datastore\n",
    "\n",
    "\n",
    "## 2.1 Working Directly with a Datastore\n",
    "\n",
    "You can work directly with a datastore to upload and download data by using the methods of the datastore class, like this:\n",
    "\n",
    "* ***upload()***\n",
    "* ***download()***\n",
    "\n",
    "Thesemethods described in the following examples are specific to, and operate identically for, the [AzureBlobDatastore](https://docs.microsoft.com/en-gb/python/api/azureml-core/azureml.data.azure_storage_datastore.azureblobdatastore?view=azure-ml-py) and [AzureFileDatastore](https://docs.microsoft.com/en-gb/python/api/azureml-core/azureml.data.azure_storage_datastore.azurefiledatastore?view=azure-ml-py) classes.\n",
    "\n",
    "> ### Upload\n",
    "Upload either a directory or individual files to the datastore by using the Python SDK:\n",
    "```python\n",
    "datastore.upload(src_dir='your source directory',\n",
    "                 target_path='your target path',\n",
    "                 overwrite=True,\n",
    "                 show_progress=True)\n",
    "```\n",
    "> The target_path parameter specifies the location in the file share (or blob container) to upload. It defaults to None, so the data is uploaded to root. If overwrite=True, any existing data at target_path is overwritten.\n",
    "You can also upload a list of individual files to the datastore via the upload_files() method\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Download\n",
    "Download data from a datastore to your local file system:\n",
    "```python\n",
    "datastore.download(target_path='your target path',\n",
    "                   prefix='your prefix',\n",
    "                   show_progress=True)\n",
    "```                   \n",
    "> The target_path parameter is the location of the local directory to download the data to. To specify a path to the folder in the file share (or blob container) to download, provide that path to prefix. If prefix is None, all the contents of your file share (or blob container) will be downloaded.\n",
    "\n",
    "In the example below, we will upload the folder **data** to our **datastore**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore.upload(src_dir='data',\n",
    "                 overwrite=True,\n",
    "                 show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will download **everything** to local **notebooks/data** folder. This is just an example and should not be tried for larger files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore.download(target_path='notebooks/data',\n",
    "                   prefix=None,\n",
    "                   show_progress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AzureDataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
